{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting future stock prices using a LSTM network\n",
    "\n",
    "This is a Jupyter notebook version of my final project for CS50x. It is a simple stock data visualiser that uses the [Alpha Vantage API](https://www.alphavantage.co/documentation/) to get stock data. I built this to give a better understanding of how I used PyTorch to build a LSTM model and used it to predict the future stock price of IBM.\n",
    "\n",
    "![IBM Stock Price Prediction](static/images/graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "To run this project, you will need to install the following packages:\n",
    "\n",
    "- [PyTorch](https://pytorch.org/)\n",
    "- [Alpha Vantage](https://pypi.org/project/alpha-vantage/)\n",
    "- [Matplotlib](https://matplotlib.org/)\n",
    "- [Numpy](https://numpy.org/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all packages\n",
    "!pip install alpha-vantage matplotlib numpy torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "To use this project, you will need to get an API key from [Alpha Vantage](https://www.alphavantage.co/support/#api-key). Once you have your API key, you will need to edit the folowing box with your API key. For this project, I have used the demo API key provided by Alpha Vantage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"alpha_vantage\": {\n",
    "        \"key\": \"demo\",  # Demo key from Alpha Vantage to test the code\n",
    "        \"symbol\": \"IBM\",  # IBM stock for demo purposes\n",
    "        \"output_size\": \"full\",\n",
    "        \"key_adjusted_close\": \"5. adjusted close\",\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"window_size\": 20,\n",
    "        \"train_split_size\": 0.80,\n",
    "    },\n",
    "    \"plots\": {\n",
    "        \"xticks_interval\": 90,  # Plot xticks every 90 days\n",
    "        \"color_actual\": \"#001f3f\",\n",
    "        \"color_train\": \"#3D9970\",\n",
    "        \"color_val\": \"#0074D9\",\n",
    "        \"color_pred_train\": \"#3D9970\",\n",
    "        \"color_pred_val\": \"#0074D9\",\n",
    "        \"color_pred_test\": \"#FF4136\",\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"input_size\": 1,  # Number of features\n",
    "        \"num_lstm_layers\": 2,\n",
    "        \"lstm_size\": 32,\n",
    "        \"dropout\": 0.2,\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"device\": \"cpu\",  # Use \"cuda\" if you have a GPU\n",
    "        # Adjust the following parameters to your needs\n",
    "        \"batch_size\": 64,\n",
    "        \"num_epoch\": 100,  # Number of epochs\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"scheduler_step_size\": 40,\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages\n",
    "\n",
    "The following code imports the packages that we will be using in this project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all packages\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "\n",
    "print(\"All packages imported.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper classes\n",
    "\n",
    "I have refactored some of the code into helper classes to make it easier to read and understand.\n",
    "\n",
    "### Normaliser\n",
    "\n",
    "This class is used to [normalise](https://en.wikipedia.org/wiki/Feature_scaling) the data.This is done to make it easier for the model to learn.\n",
    "\n",
    "### LSTMModel\n",
    "\n",
    "This class is used to build the LSTM model. It is a simple 2 layer LSTM model with 1 output layer. Using configurations (created above), it is possible to change the number of layers, the number of neurons in each layer, and the number of epochs.\n",
    "\n",
    "### TimeSeriesDataset\n",
    "\n",
    "This class is used to create a dataset from the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data analysis\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class Normalizer:\n",
    "    def __init__(self):\n",
    "        self.mu = None\n",
    "        self.sd = None\n",
    "\n",
    "    def fit_transform(self, x):\n",
    "        self.mu = np.mean(x, axis=(0), keepdims=True)\n",
    "        self.sd = np.std(x, axis=(0), keepdims=True)\n",
    "        normalized_x = (x - self.mu) / self.sd\n",
    "        return normalized_x\n",
    "\n",
    "    def inverse_transform(self, x):\n",
    "        return (x * self.sd) + self.mu\n",
    "\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size=1,\n",
    "        hidden_layer_size=32,\n",
    "        num_layers=2,\n",
    "        output_size=1,\n",
    "        dropout=0.2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.linear_1 = nn.Linear(input_size, hidden_layer_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lstm = nn.LSTM(\n",
    "            hidden_layer_size,\n",
    "            hidden_size=self.hidden_layer_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(num_layers * hidden_layer_size, output_size)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for name, param in self.lstm.named_parameters():\n",
    "            if \"bias\" in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif \"weight_ih\" in name:\n",
    "                nn.init.kaiming_normal_(param)\n",
    "            elif \"weight_hh\" in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "\n",
    "        # Layer 1\n",
    "        x = self.linear_1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # LSTM\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "\n",
    "        # Reshape from hidden cell\n",
    "        x = h_n.permute(1, 0, 2).reshape(batchsize, -1)\n",
    "\n",
    "        # Layer 2\n",
    "        x = self.dropout(x)\n",
    "        predictions = self.linear_2(x)\n",
    "        return predictions[:, -1]\n",
    "\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        x = np.expand_dims(\n",
    "            x, 2\n",
    "        )  # Convert `x` into [batch, sequence, features] for LSTM\n",
    "        self.x = x.astype(np.float32)\n",
    "        self.y = y.astype(np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.x[idx], self.y[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data analysis\n",
    "import numpy as np\n",
    "\n",
    "# API\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "\n",
    "\n",
    "def download_data(config):\n",
    "    \"\"\"\n",
    "    Download data from Alpha Vantage API\n",
    "    \"\"\"\n",
    "    ts = TimeSeries(key=config[\"alpha_vantage\"][\"key\"])\n",
    "\n",
    "    data, meta_data = ts.get_daily_adjusted(\n",
    "        symbol=config[\"alpha_vantage\"][\"symbol\"],\n",
    "        outputsize=config[\"alpha_vantage\"][\"output_size\"],\n",
    "    )\n",
    "\n",
    "    dates = [date for date in data.keys()]\n",
    "    dates.reverse()\n",
    "\n",
    "    close_prices = [\n",
    "        float(data[date][config[\"alpha_vantage\"][\"key_adjusted_close\"]])\n",
    "        for date in data.keys()\n",
    "    ]\n",
    "    close_prices.reverse()\n",
    "    close_prices = np.array(close_prices)\n",
    "\n",
    "    num_data_points = len(dates)\n",
    "\n",
    "    display_date_range = (\n",
    "        \"from {} to {}\".format(dates[0], dates[num_data_points - 1])\n",
    "        if num_data_points > 1\n",
    "        else dates[0]\n",
    "    )\n",
    "\n",
    "    print(f\"Downloaded {num_data_points} data points {display_date_range}.\")\n",
    "\n",
    "    return dates, close_prices, num_data_points, display_date_range\n",
    "\n",
    "\n",
    "def prepare_x(x, window_size):\n",
    "    output = np.lib.stride_tricks.as_strided(\n",
    "        x,\n",
    "        shape=(x.shape[0] - window_size + 1, window_size),\n",
    "        strides=(x.strides[0], x.strides[0]),\n",
    "    )\n",
    "    return output[:-1], output[-1]\n",
    "\n",
    "\n",
    "def prepare_y(x, window_size):\n",
    "    return x[window_size:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver code\n",
    "\n",
    "This is the main chunk of code that runs the project. It contains the following steps:\n",
    "\n",
    "1. Get the stock data\n",
    "2. Prepare the data for the model\n",
    "3. Create the model\n",
    "4. Train the model\n",
    "5. Predict the future stock price\n",
    "6. Visualise the data\n",
    "\n",
    "### Prepare the data for the model\n",
    "\n",
    "Prepares the data for the model. It does the following:\n",
    "\n",
    "1. Normalise the data\n",
    "2. Create a dataset from the data\n",
    "3. Split the data into training and testing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_date, data_close_price, num_data_points, display_date_range = download_data(config)\n",
    "\n",
    "# Normalize data\n",
    "scaler = Normalizer()\n",
    "normalized_data_close_price = scaler.fit_transform(data_close_price)\n",
    "\n",
    "data_x, _data_x = prepare_x(\n",
    "    normalized_data_close_price, window_size=config[\"data\"][\"window_size\"]\n",
    ")\n",
    "\n",
    "data_y = prepare_y(\n",
    "    normalized_data_close_price, window_size=config[\"data\"][\"window_size\"]\n",
    ")\n",
    "\n",
    "# Split data into train and test\n",
    "split_index = int(data_y.shape[0] * config[\"data\"][\"train_split_size\"])\n",
    "\n",
    "data_x_train = data_x[:split_index]\n",
    "data_x_val = data_x[split_index:]\n",
    "\n",
    "data_y_train = data_y[:split_index]\n",
    "data_y_val = data_y[split_index:]\n",
    "\n",
    "\n",
    "# Create dataset and dataloader for training\n",
    "dataset_train = TimeSeriesDataset(data_x_train, data_y_train)\n",
    "dataset_val = TimeSeriesDataset(data_x_val, data_y_val)\n",
    "\n",
    "print(\"Train data shape:\", dataset_train.x.shape, dataset_train.y.shape)\n",
    "print(\"Validation data shape:\", dataset_val.x.shape, dataset_val.y.shape)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset_train, batch_size=config[\"training\"][\"batch_size\"], shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    dataset_val, batch_size=config[\"training\"][\"batch_size\"], shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model\n",
    "\n",
    "Builds the LSTM model using the configurations created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel(\n",
    "    input_size=config[\"model\"][\"input_size\"],\n",
    "    hidden_layer_size=config[\"model\"][\"lstm_size\"],\n",
    "    num_layers=config[\"model\"][\"num_lstm_layers\"],\n",
    "    output_size=1,\n",
    "    dropout=config[\"model\"][\"dropout\"],\n",
    ")\n",
    "\n",
    "model = model.to(config[\"training\"][\"device\"])\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=config[\"training\"][\"learning_rate\"],\n",
    "    betas=(0.9, 0.98),\n",
    "    eps=1e-9,\n",
    ")\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(\n",
    "    optimizer, step_size=config[\"training\"][\"scheduler_step_size\"], gamma=0.1\n",
    ")\n",
    "\n",
    "# Run an epoch\n",
    "def run_epoch(dataloader, is_training=False):\n",
    "    epoch_loss = 0\n",
    "\n",
    "    if is_training:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    for idx, (x, y) in enumerate(dataloader):\n",
    "        if is_training:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        batchsize = x.shape[0]\n",
    "\n",
    "        x = x.to(config[\"training\"][\"device\"])\n",
    "        y = y.to(config[\"training\"][\"device\"])\n",
    "\n",
    "        out = model(x)\n",
    "        loss = criterion(out.contiguous(), y.contiguous())\n",
    "\n",
    "        if is_training:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.detach().item() / batchsize\n",
    "\n",
    "    lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "    return epoch_loss, lr\n",
    "\n",
    "\n",
    "for epoch in range(config[\"training\"][\"num_epoch\"]):\n",
    "    loss_train, lr_train = run_epoch(train_dataloader, is_training=True)\n",
    "    loss_val, lr_val = run_epoch(val_dataloader)\n",
    "    scheduler.step()\n",
    "\n",
    "    print(\n",
    "        \"Epoch {}/{} | Loss - train: {:.6f} test: {:.6f} | lr: {:.6f}\".format(\n",
    "            epoch + 1, config[\"training\"][\"num_epoch\"], loss_train, loss_val, lr_train\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# Re-initialize dataloader so data doesn't shuffle\n",
    "# Plot the values by date\n",
    "train_dataloader = DataLoader(\n",
    "    dataset_train, batch_size=config[\"training\"][\"batch_size\"], shuffle=False\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    dataset_val, batch_size=config[\"training\"][\"batch_size\"], shuffle=False\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Predict on the training data\n",
    "predicted_train = np.array([])\n",
    "\n",
    "for idx, (x, y) in enumerate(train_dataloader):\n",
    "    x = x.to(config[\"training\"][\"device\"])\n",
    "    out = model(x)\n",
    "    out = out.cpu().detach().numpy()\n",
    "    predicted_train = np.concatenate((predicted_train, out))\n",
    "\n",
    "# Predict on the validation data\n",
    "predicted_val = np.array([])\n",
    "\n",
    "for idx, (x, y) in enumerate(val_dataloader):\n",
    "    x = x.to(config[\"training\"][\"device\"])\n",
    "    out = model(x)\n",
    "    out = out.cpu().detach().numpy()\n",
    "    predicted_val = np.concatenate((predicted_val, out))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the data\n",
    "\n",
    "Plots the data using matplotlib. It plots the following:\n",
    "\n",
    "1. The actual stock price\n",
    "2. The predicted stock price\n",
    "3. The difference between the actual and predicted stock price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for plotting\n",
    "y_train_pred = np.zeros(num_data_points)\n",
    "y_val_pred = np.zeros(num_data_points)\n",
    "\n",
    "y_train_pred[\n",
    "    config[\"data\"][\"window_size\"] : split_index + config[\"data\"][\"window_size\"]\n",
    "] = scaler.inverse_transform(predicted_train)\n",
    "\n",
    "y_val_pred[split_index + config[\"data\"][\"window_size\"] :] = scaler.inverse_transform(\n",
    "    predicted_val\n",
    ")\n",
    "\n",
    "y_train_pred = np.where(y_train_pred == 0, None, y_train_pred)\n",
    "y_val_pred = np.where(y_val_pred == 0, None, y_val_pred)\n",
    "\n",
    "# Plot the values by date\n",
    "fig = figure(figsize=(25, 5), dpi=80)\n",
    "fig.patch.set_facecolor((1.0, 1.0, 1.0))\n",
    "\n",
    "plt.title(\n",
    "    \"Compare predicted prices to actual prices for {}\".format(\n",
    "        config[\"alpha_vantage\"][\"symbol\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "xticks = [\n",
    "    data_date[i]\n",
    "    if (\n",
    "        (\n",
    "            i % config[\"plots\"][\"xticks_interval\"] == 0\n",
    "            and (num_data_points - i) > config[\"plots\"][\"xticks_interval\"]\n",
    "        )\n",
    "        or i == num_data_points - 1\n",
    "    )\n",
    "    else None\n",
    "    for i in range(num_data_points)\n",
    "]\n",
    "\n",
    "x = np.arange(0, len(xticks))\n",
    "plt.xticks(x, xticks, rotation=\"vertical\")\n",
    "plt.grid(visible=True, which=\"major\", axis=\"y\", linestyle=\"--\")\n",
    "\n",
    "plt.ylabel(\"Price (USD)\")\n",
    "\n",
    "plt.plot(\n",
    "    data_date,\n",
    "    data_close_price,\n",
    "    label=\"Actual prices\",\n",
    "    color=config[\"plots\"][\"color_actual\"],\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    data_date,\n",
    "    y_train_pred,\n",
    "    label=\"Predicted prices (train)\",\n",
    "    color=config[\"plots\"][\"color_pred_train\"],\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    data_date,\n",
    "    y_val_pred,\n",
    "    label=\"Predicted prices (validation)\",\n",
    "    color=config[\"plots\"][\"color_pred_val\"],\n",
    ")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plotting the zoomed in view of the predicted prices vs. actual prices\n",
    "y_val_subset = scaler.inverse_transform(data_y_val)\n",
    "predicted_val = scaler.inverse_transform(predicted_val)\n",
    "date = data_date[split_index + config[\"data\"][\"window_size\"] :]\n",
    "\n",
    "fig = figure(figsize=(25, 5), dpi=80)\n",
    "fig.patch.set_facecolor((1.0, 1.0, 1.0))\n",
    "\n",
    "plt.title(\"Zoom in to examine predicted price on validation data portion\")\n",
    "\n",
    "xticks = [\n",
    "    date[i]\n",
    "    if (\n",
    "        (\n",
    "            i % int(config[\"plots\"][\"xticks_interval\"] / 5) == 0\n",
    "            and (len(date) - i) > config[\"plots\"][\"xticks_interval\"] / 6\n",
    "        )\n",
    "        or i == len(date) - 1\n",
    "    )\n",
    "    else None\n",
    "    for i in range(len(date))\n",
    "]\n",
    "\n",
    "xs = np.arange(0, len(xticks))\n",
    "plt.xticks(xs, xticks, rotation=\"vertical\")\n",
    "plt.grid(visible=True, which=\"major\", axis=\"y\", linestyle=\"--\")\n",
    "\n",
    "plt.ylabel(\"Price (USD)\")\n",
    "\n",
    "plt.plot(\n",
    "    date,\n",
    "    y_val_subset,\n",
    "    label=\"Actual prices\",\n",
    "    color=config[\"plots\"][\"color_actual\"],\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    date,\n",
    "    predicted_val,\n",
    "    label=\"Predicted prices (validation)\",\n",
    "    color=config[\"plots\"][\"color_pred_val\"],\n",
    ")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Predict the closing price of the next trading day\n",
    "model.eval()\n",
    "\n",
    "x = (\n",
    "    torch.tensor(_data_x)\n",
    "    .float()\n",
    "    .to(config[\"training\"][\"device\"])\n",
    "    .unsqueeze(0)\n",
    "    .unsqueeze(2)\n",
    ")\n",
    "\n",
    "prediction = model(x)\n",
    "prediction = prediction.cpu().detach().numpy()\n",
    "\n",
    "plot_range = 10\n",
    "y_test_pred = np.zeros(plot_range)\n",
    "\n",
    "y_test_pred[plot_range - 1] = scaler.inverse_transform(prediction)\n",
    "\n",
    "y_test_pred = np.where(y_test_pred == 0, None, y_test_pred)\n",
    "\n",
    "print(\n",
    "    \"Predicted close price of the next trading day: ${:.2f}\".format(\n",
    "        y_test_pred[plot_range - 1]\n",
    "    )\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44dd0237562f3421fb645684fc0f8b3767186d308504295d4e2333cb963f60c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
